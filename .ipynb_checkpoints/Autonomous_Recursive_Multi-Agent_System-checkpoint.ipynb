{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f7dd8-2e1e-43e6-af25-65999d6c7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===== main.py =====\n",
    "from commander_agent import Commander\n",
    "\n",
    "def main():\n",
    "    commander = Commander()\n",
    "    user_goal = input(\"請輸入你的任務需求：\")\n",
    "    commander.receive_goal(user_goal)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "### ===== commander_agent.py =====\n",
    "import openai\n",
    "from expert_factory import ExpertFactory\n",
    "from communication import Communicator\n",
    "from memory import Memory\n",
    "\n",
    "openai.api_key = \"YOUR_OPENAI_API_KEY\"  # 請替換成你的 API Key\n",
    "\n",
    "class Commander:\n",
    "    def __init__(self):\n",
    "        self.memory = Memory()\n",
    "        self.communicator = Communicator(self.memory)\n",
    "\n",
    "    def receive_goal(self, goal):\n",
    "        print(f\"\\n[Commander] 收到任務：{goal}\")\n",
    "        self.analyze_and_create_experts(goal)\n",
    "\n",
    "    def analyze_and_create_experts(self, goal):\n",
    "        print(\"[Commander] 使用 LLM 推理需要哪些專家...\\n\")\n",
    "        expert_roles = self.llm_determine_experts(goal)\n",
    "        experts = [ExpertFactory.create_dynamic_expert(role, self.communicator) for role in expert_roles]\n",
    "        self.communicator.assign_tasks(experts)\n",
    "        self.communicator.coordinate()\n",
    "        self.final_report()\n",
    "\n",
    "    def llm_determine_experts(self, goal):\n",
    "        prompt = f\"\"\"\n",
    "你是一位任務規劃師。根據下列任務，列出需要的專家角色，每個角色一句話描述其負責的工作：\n",
    "任務：「{goal}」\n",
    "請以以下格式回答：\n",
    "角色名稱：職責描述\n",
    "角色名稱：職責描述\n",
    "...\"\"\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=[{\"role\": \"system\", \"content\": \"你是專業的AI任務規劃助手。\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        content = response['choices'][0]['message']['content']\n",
    "        expert_list = []\n",
    "        for line in content.strip().split(\"\\n\"):\n",
    "            if \":\" in line:\n",
    "                role, _ = line.split(\":\", 1)\n",
    "                expert_list.append(role.strip())\n",
    "        return expert_list\n",
    "\n",
    "    def final_report(self):\n",
    "        print(\"\\n[Commander] 任務完成，以下是總結：\")\n",
    "        print(self.memory.collect_all_notes())\n",
    "\n",
    "\n",
    "### ===== expert_factory.py =====\n",
    "class ExpertFactory:\n",
    "    @staticmethod\n",
    "    def create_dynamic_expert(role, communicator):\n",
    "        return DynamicExpert(role, communicator)\n",
    "\n",
    "class DynamicExpert:\n",
    "    def __init__(self, role, communicator):\n",
    "        self.role = role\n",
    "        self.communicator = communicator\n",
    "\n",
    "    def act(self, context):\n",
    "        self_output = f\"[{self.role}] 初步完成了子任務。\"\n",
    "        context.add_message(self.role, self_output)\n",
    "\n",
    "        others_output = context.get_recent_messages(exclude=self.role)\n",
    "        if others_output:\n",
    "            for msg in others_output:\n",
    "                reply = f\"[{self.role}] 根據 {msg['sender']} 的資訊補充了內容。\"\n",
    "                context.add_message(self.role, reply)\n",
    "\n",
    "        self.communicator.submit_work(self.role, f\"{self.role} 討論後的最終結果\")\n",
    "\n",
    "\n",
    "### ===== communication.py =====\n",
    "class Communicator:\n",
    "    def __init__(self, memory):\n",
    "        self.memory = memory\n",
    "        self.messages = []\n",
    "\n",
    "    def assign_tasks(self, experts):\n",
    "        self.experts = experts\n",
    "\n",
    "    def coordinate(self):\n",
    "        for expert in self.experts:\n",
    "            try:\n",
    "                expert.act(self)\n",
    "            except Exception as e:\n",
    "                print(f\"[警告] {expert.role} 遇到問題: {str(e)}\")\n",
    "                if self.should_ask_user(e):\n",
    "                    answer = input(\"是否需要協助？(y/n)：\")\n",
    "                    if answer.lower() == 'y':\n",
    "                        suggestion = input(\"請提供你的建議：\")\n",
    "                        self.memory.record_note(\"User Intervention\", suggestion)\n",
    "                    else:\n",
    "                        self.memory.record_note(\"Commander Decision\", \"自動跳過問題繼續執行\")\n",
    "                else:\n",
    "                    self.memory.record_note(\"Commander Decision\", \"自動處理異常\")\n",
    "\n",
    "    def submit_work(self, expert_role, result):\n",
    "        self.memory.record_note(expert_role, result)\n",
    "\n",
    "    def add_message(self, sender, content):\n",
    "        self.messages.append({\"sender\": sender, \"content\": content})\n",
    "\n",
    "    def get_recent_messages(self, exclude=None):\n",
    "        return [msg for msg in self.messages if msg['sender'] != exclude]\n",
    "\n",
    "    def should_ask_user(self, error):\n",
    "        return True  # 可根據錯誤內容判斷，這裡簡化為一律詢問\n",
    "\n",
    "\n",
    "### ===== memory.py =====\n",
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.notes = []\n",
    "\n",
    "    def record_note(self, role, content):\n",
    "        self.notes.append(f\"{role}完成：{content}\")\n",
    "\n",
    "    def collect_all_notes(self):\n",
    "        return \"\\n\".join(self.notes)\n",
    "\n",
    "\n",
    "### ===== requirements.txt =====\n",
    "openai\n",
    "langchain\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
